{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010b230c",
   "metadata": {},
   "source": [
    "# 1 - Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbf5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install kornia \n",
    "!pip install fastai\n",
    "!pip install opencv-python\n",
    "!pip install imageio\n",
    "!pip install nibabel\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376eefb6",
   "metadata": {},
   "source": [
    "# 2 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import *\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc5337",
   "metadata": {},
   "source": [
    "# 3 - Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a meta file for the nifti files\n",
    "    \n",
    "file_list = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('D:\\Datasets\\liverSegmentation\\input'):\n",
    "    for filename in filenames:\n",
    "        file_list.append((dirname,filename))\n",
    "        \n",
    "df_files = pd.DataFrame(file_list, columns=['dirname', 'filename'])\n",
    "df_files.sort_values(by=['filename'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bdb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map CT scan and segmentation\n",
    "\n",
    "df_files[\"mask_dirname\"] = \"\"\n",
    "df_files[\"mask_filename\"] = \"\"\n",
    "\n",
    "for i in range(int(len(file_list)/2)):\n",
    "    ct = f\"volume-{i}.nii\"\n",
    "    mask = f\"segmentation-{i}.nii\"\n",
    "    \n",
    "    df_files.loc[df_files['filename'] == ct, 'mask_filename'] =  mask\n",
    "    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = 'D:\\Datasets\\liverSegmentation\\input\\segmentations'\n",
    "    \n",
    "# delete segmentation rows\n",
    "df_files = df_files[df_files.mask_filename != \"\"].sort_values(by=['filename']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nii(fpath):\n",
    "    \"\"\"\n",
    "    Reads in a .nii file and returns a pixel array\n",
    "    \"\"\"\n",
    "    \n",
    "    scan = nib.load(fpath)\n",
    "    array = scan.get_fdata()\n",
    "    array = np.rot90(np.array(array))\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe80c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample\n",
    "\n",
    "sample = 0\n",
    "sample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\n",
    "sample_mask = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n",
    "\n",
    "print(f'CT Shape:   {sample_ct.shape}\\nMask Shape: {sample_mask.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_ct[:,:,55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ccfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the nii file \n",
    "# Source https://docs.fast.ai/medical.imaging\n",
    "\n",
    "dicom_windows = types.SimpleNamespace(\n",
    "    brain=(80,40),\n",
    "    subdural=(254,100),\n",
    "    stroke=(8,32),\n",
    "    brain_bone=(2800,600),\n",
    "    brain_soft=(375,40),\n",
    "    lungs=(1500,-600),\n",
    "    mediastinum=(350,50),\n",
    "    abdomen_soft=(400,50),\n",
    "    liver=(150,30),\n",
    "    spine_soft=(250,50),\n",
    "    spine_bone=(1800,400),\n",
    "    custom = (200,60)\n",
    ")\n",
    "\n",
    "@patch\n",
    "def windowed(self:Tensor, w, l):\n",
    "    px = self.clone()\n",
    "    px_min = l - w//2\n",
    "    px_max = l + w//2\n",
    "    px[px<px_min] = px_min\n",
    "    px[px>px_max] = px_max\n",
    "    return (px-px_min) / (px_max-px_min)\n",
    "\n",
    "figure(figsize=(8, 6), dpi=100)\n",
    "\n",
    "plt.imshow(tensor(sample_ct[..., 55].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(array_list : list, color_map = 'nipy_spectral'):\n",
    "    \"\"\"\n",
    "    Plots a slice with all available annotations\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20,16), dpi=100)\n",
    "    \n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(array_list[0], cmap='bone')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n",
    "    plt.title('Windowed Image')\n",
    "    plt.axis('off')\n",
    "             \n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(array_list[0], cmap='bone')\n",
    "    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n",
    "    plt.title('Liver & Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 55\n",
    "\n",
    "sample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n",
    "\n",
    "plot_sample([sample_ct[..., sample],\n",
    "             sample_mask[..., sample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "# Source https://docs.fast.ai/medical.imaging.html\n",
    "\n",
    "class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n",
    "    \n",
    "@patch\n",
    "def freqhist_bins(self:Tensor, n_bins = 100):\n",
    "    \"\"\"\n",
    "    Function to split the range of pixel values into groups, such that each group has approximately the same number of pixels.\n",
    "    \"\"\"\n",
    "    imsd = self.view(-1).sort()[0]\n",
    "    t = torch.cat([tensor([0.001]),\n",
    "                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n",
    "                   tensor([0.999])])\n",
    "    t = (len(imsd)*t).long()\n",
    "    bins = imsd[t].unique()\n",
    "    return bins\n",
    "\n",
    "@patch\n",
    "def hist_scaled(self:Tensor, brks=None):\n",
    "    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n",
    "    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n",
    "    if brks is None: brks = self.freqhist_bins()\n",
    "    ys = np.linspace(0., 1., len(brks))\n",
    "    x = self.numpy().flatten()\n",
    "    x = np.interp(x, brks.numpy(), ys)\n",
    "    return tensor(x).reshape(self.shape).clamp(0.,1.)\n",
    "    \n",
    "    \n",
    "@patch\n",
    "def to_nchan(x:Tensor, wins, bins=None):\n",
    "    res = [x.windowed(*win) for win in wins]\n",
    "    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n",
    "    dim = [0,1][x.dim()==3]\n",
    "    return TensorCTScan(torch.stack(res, dim=dim))\n",
    "\n",
    "@patch\n",
    "def save_jpg(x:(Tensor), path, wins, bins=None, quality=120):\n",
    "    fn = Path(path).with_suffix('.jpg')\n",
    "    x = (x.to_nchan(wins, bins)*255).byte()\n",
    "    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n",
    "    im.save(fn, quality=quality)\n",
    "\n",
    "_,axs = subplots(1,1)\n",
    "\n",
    "sample_slice.save_jpg('test.jpg', [dicom_windows.liver, dicom_windows.custom])\n",
    "show_image(Image.open('test.jpg'), ax=axs[0], figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make custom JPG files for Unet training\n",
    "# Total number of 131 nii files contains 67072 slices \n",
    "\n",
    "GENERATE_JPG_FILES = False\n",
    "\n",
    "if (GENERATE_JPG_FILES) :\n",
    "    \n",
    "    path = Path(\"D:\\Datasets\\liverSegmentation\\preprocessed\")\n",
    "\n",
    "    os.makedirs(os.path.join(path,'train_images'),exist_ok=True)\n",
    "    os.makedirs(os.path.join(path,'train_masks'),exist_ok=True)\n",
    "\n",
    "    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n",
    "        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n",
    "        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n",
    "        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n",
    "        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n",
    "\n",
    "        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n",
    "            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n",
    "            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode=\"L\")\n",
    "            data.save_jpg(f\"{os.path.join(path,'train_images')}/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n",
    "            mask.save(f\"{os.path.join(path,'train_masks')}/{curr_file_name}_slice_{curr_slice}_mask.png\")\n",
    "else:\n",
    "    path = Path(\"D:\\Datasets\\liverSegmentation\\preprocessed\") # read jpg from saved kernel output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f4405",
   "metadata": {},
   "source": [
    "# 3 - Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3c442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 128\n",
    "\n",
    "codes = np.array([\"background\",\"liver\",\"tumor\"])\n",
    "\n",
    "def get_x(fname:Path): return fname\n",
    "def label_func(x): return path/'train_masks'/f'{x.stem}_mask.png'\n",
    "\n",
    "tfms = [IntToFloatTensor(),Normalize()]\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),\n",
    "               batch_tfms = tfms,\n",
    "               splitter = RandomSplitter(),\n",
    "               item_tfms = [Resize(IMG_SIZE)],\n",
    "               get_items = get_image_files,\n",
    "               get_y = label_func\n",
    "              )\n",
    "\n",
    "ds = db.datasets(source = path/'train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30\n",
    "imgs = [ds[idx][0],ds[idx][1]]\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(path/'train_images', bs = BATCH_SIZE) #, num_workers=0\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc674a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreground_acc(inp, targ, bkg_idx=0, axis=1):  # exclude a background from metric\n",
    "    \"Computes non-background accuracy for multiclass segmentation\"\n",
    "    targ = targ.squeeze(1)\n",
    "    mask = targ != bkg_idx\n",
    "    return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean() \n",
    "\n",
    "def cust_foreground_acc(inp, targ):  # # include a background into the metric\n",
    "    return foreground_acc(inp=inp, targ=targ, bkg_idx=3, axis=1) # 3 is a dummy value to include the background which is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls,\n",
    "                     resnet18,\n",
    "                     loss_func=CrossEntropyLossFlat(axis=1),\n",
    "                     metrics=[foreground_acc, cust_foreground_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944daf02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(5, wd=0.1, cbs=SaveModelCallback() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba3905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
